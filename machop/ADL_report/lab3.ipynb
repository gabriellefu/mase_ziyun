{"cells":[{"cell_type":"markdown","metadata":{"id":"2lOvsvPyA_QJ"},"source":["# Installing MASE (again)\n","\n","Run the block below to install MASE in the current Colab runtime"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"63pyg-QhA6NE"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.10.13\n","^C\n","Traceback (most recent call last):\n","  File \"/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/rds/general/user/zf923/home/.local/lib/python3.10/site-packages/pip/__main__.py\", line 22, in <module>\n","    from pip._internal.cli.main import main as _main\n","  File \"/rds/general/user/zf923/home/.local/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 10, in <module>\n","    from pip._internal.cli.autocompletion import autocomplete\n","  File \"/rds/general/user/zf923/home/.local/lib/python3.10/site-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n","    from pip._internal.cli.main_parser import create_main_parser\n","  File \"/rds/general/user/zf923/home/.local/lib/python3.10/site-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n","    from pip._internal.build_env import get_runnable_pip\n","  File \"/rds/general/user/zf923/home/.local/lib/python3.10/site-packages/pip/_internal/build_env.py\", line 15, in <module>\n","    from pip._vendor.packaging.requirements import Requirement\n","  File \"/rds/general/user/zf923/home/.local/lib/python3.10/site-packages/pip/_vendor/packaging/requirements.py\", line 10, in <module>\n","    from pip._vendor.pyparsing import (  # noqa\n","  File \"/rds/general/user/zf923/home/.local/lib/python3.10/site-packages/pip/_vendor/pyparsing/__init__.py\", line 136, in <module>\n","    from .helpers import *  # type: ignore[misc, assignment]\n","  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n","  File \"<frozen importlib._bootstrap_external>\", line 975, in get_code\n","  File \"<frozen importlib._bootstrap_external>\", line 1074, in get_data\n","KeyboardInterrupt\n","Cloning into 'mase'...\n","fatal: Remote branch lab1_YOUR_SHORT_CODE not found in upstream origin\n","\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: './mase/machop/requirements.txt'\u001b[0m\u001b[31m\n","\u001b[0m[Errno 2] No such file or directory: './mase/machop/'\n","/rds/general/user/zf923/home/mase_ziyun/machop/ADL Lab result\n"]},{"name":"stderr","output_type":"stream","text":["/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n","  bkms = self.shell.db.get('bookmarks', {})\n"]}],"source":["git_token = \"YOUR_GIT_TOKEN\"\n","short_code = \"YOUR_SHORT_CODE\"\n","\n","# Check the current python version (It should be using Python 3.10) and update pip to the latest version.\n","!python --version\n","!python -m pip install --user --upgrade pip\n","\n","# Clone MASE from your branch (the branch must already exist)\n","!git clone -b lab1_{short_code} https://{git_token}@github.com/DeepWok/mase.git\n","\n","# Install requirements\n","!python -m pip install -r ./mase/machop/requirements.txt\n","\n","# Change working directory to machop\n","%cd ./mase/machop/"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/workspaces/mase/machop\n"]}],"source":["cd .."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cWmuJFOZBG16"},"outputs":[{"name":"stdout","output_type":"stream","text":["/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n","  return torch._C._cuda_getDeviceCount() > 0\n","/rds/general/user/zf923/home/mase_ziyun/machop/chop/actions/simulate.py:3: UserWarning: Python runners and associated APIs are an experimental feature and subject to change.\n","  from cocotb.runner import get_runner, get_results\n","usage: ch [--config PATH] [--task TASK] [--load PATH] [--load-type]\n","          [--batch-size NUM] [--debug] [--log-level]\n","          [--report-to {wandb,tensorboard}] [--seed NUM] [--quant-config TOML]\n","          [--training-optimizer TYPE] [--trainer-precision TYPE]\n","          [--learning-rate NUM] [--weight-decay NUM] [--max-epochs NUM]\n","          [--max-steps NUM] [--accumulate-grad-batches NUM]\n","          [--log-every-n-steps NUM] [--cpu NUM] [--gpu NUM] [--nodes NUM]\n","          [--accelerator TYPE] [--strategy TYPE] [--auto-requeue]\n","          [--github-ci] [--disable-dataset-cache] [--target STR]\n","          [--num-targets NUM] [--run-emit] [--skip-build] [--skip-test]\n","          [--pretrained] [--max-token-len NUM] [--project-dir DIR]\n","          [--project NAME] [--profile] [--no-warnings] [-h] [-V]\n","          [--info [TYPE]]\n","          action [model] [dataset]\n","\n","Chop is a simple utility, part of the MASE tookit, to train, test and\n","transform (i.e. prune or quantise) a supported model.\n","\n","main arguments:\n","  action                action to perform. One of\n","                        (train|test|transform|search|emit|simulate)\n","  model                 name of a supported model. Required if configuration\n","                        NOT provided.\n","  dataset               name of a supported dataset. Required if configuration\n","                        NOT provided.\n","\n","general options:\n","  --config PATH         path to a configuration file in the TOML format.\n","                        Manual CLI overrides for arguments have a higher\n","                        precedence. Required if the action is transform.\n","                        (default: None)\n","  --task TASK           task to perform. One of (classification|cls|translatio\n","                        n|tran|language_modeling|lm) (default: classification)\n","  --load PATH           path to load the model from. (default: None)\n","  --load-type           the type of checkpoint to be loaded; it's disregarded\n","                        if --load is NOT specified. It is designed to and must\n","                        be used in tandem with --load. One of (pt|pl|mz|hf)\n","                        (default: mz)\n","  --batch-size NUM      batch size for training and evaluation. (default: 128)\n","  --debug               run the action in debug mode, which enables verbose\n","                        logging, custom exception hook that uses ipdb, and\n","                        sets the PL trainer to run in \"fast_dev_run\" mode.\n","                        (default: False)\n","  --log-level           verbosity level of the logger; it's only effective\n","                        when --debug flag is NOT passed in. One of\n","                        (debug|info|warning|error|critical) (default: info)\n","  --report-to {wandb,tensorboard}\n","                        reporting tool for logging metrics. One of\n","                        (wandb|tensorboard) (default: tensorboard)\n","  --seed NUM            seed for random number generators set via Pytorch\n","                        Lightning's seed_everything function. (default: 0)\n","  --quant-config TOML   path to a configuration file in the TOML format.\n","                        Manual CLI overrides for arguments have a higher\n","                        precedence. (default: None)\n","\n","trainer options:\n","  --training-optimizer TYPE\n","                        name of supported optimiser for training. One of\n","                        (adam|sgd|adamw) (default: adam)\n","  --trainer-precision TYPE\n","                        numeric precision for training. One of\n","                        (16-mixed|32|64|bf16) (default: 16-mixed)\n","  --learning-rate NUM   initial learning rate for training. (default: 1e-05)\n","  --weight-decay NUM    weight decay for training. (default: 0)\n","  --max-epochs NUM      maximum number of epochs for training. (default: 20)\n","  --max-steps NUM       maximum number of steps for training. A negative value\n","                        disables this option. (default: -1)\n","  --accumulate-grad-batches NUM\n","                        number of batches to accumulate gradients. (default:\n","                        1)\n","  --log-every-n-steps NUM\n","                        log every n steps. No logs if num_batches <\n","                        log_every_n_steps. (default: 50))\n","\n","runtime environment options:\n","  --cpu NUM, --num-workers NUM\n","                        number of CPU workers; the default varies across\n","                        systems and is set to os.cpu_count(). (default: 256)\n","  --gpu NUM, --num-devices NUM\n","                        number of GPU devices. (default: 1)\n","  --nodes NUM           number of nodes. (default: 1)\n","  --accelerator TYPE    type of accelerator for training. One of\n","                        (auto|cpu|gpu|mps) (default: auto)\n","  --strategy TYPE       type of strategy for training. One of\n","                        (auto|ddp|ddp_find_unused_parameters_true) (default:\n","                        auto)\n","  --auto-requeue        enable automatic job resubmission on SLURM managed\n","                        cluster. (default: False)\n","  --github-ci           set the execution environment to GitHub's CI pipeline;\n","                        it's used in the MASE verilog emitter transform pass\n","                        to skip simulations. (default: False)\n","  --disable-dataset-cache\n","                        disable caching of datasets. (default: False)\n","\n","hardware generation options:\n","  --target STR          target FPGA for hardware synthesis. (default:\n","                        xcu250-figd2104-2L-e)\n","  --num-targets NUM     number of FPGA devices. (default: 100)\n","  --run-emit\n","  --skip-build\n","  --skip-test\n","\n","language model options:\n","  --pretrained          load pretrained checkpoint from\n","                        HuggingFace/Torchvision when initialising models.\n","                        (default: False)\n","  --max-token-len NUM   maximum number of tokens. A negative value will use\n","                        tokenizer.model_max_length. (default: 512)\n","\n","project options:\n","  --project-dir DIR     directory to save the project to. (default:\n","                        /rds/general/user/zf923/home/mase_ziyun/mase_output)\n","  --project NAME        name of the project. (default: {MODEL-NAME}_{TASK-\n","                        TYPE}_{DATASET-NAME}_{TIMESTAMP})\n","  --profile\n","  --no-warnings\n","\n","information:\n","  -h, --help            show this help message and exit\n","  -V, --version         show version and exit\n","  --info [TYPE]         list information about supported models or/and\n","                        datasets and exit. One of (all|model|dataset)\n","                        (default: all)\n","\n","Maintained by the DeepWok Lab. Raise issues at\n","https://github.com/JianyiCheng/mase-tools/issues\n"]}],"source":["\n","!./ch --help"]},{"cell_type":"markdown","metadata":{"id":"quwHu5RREX5z"},"source":["# General introduction\n","\n","In this lab, you will learn how to use the search functionality in the software stack of MASE.\n","\n","There are in total 4 tasks you would need to finish.\n","\n","# Writing a search using MaseGraph Transforms\n","\n","In this section, our objective is to gain a comprehensive understanding of the construction of the current search function in Mase. To achieve this, we will require these essential components:\n","\n","- MaseGraph: This component should be already created in the preceding lab.\n","- Search space: This component encompasses and defines the various available search options.\n","- Search strategy: An implementation of a search algorithm.\n","- Runner: This vital component manages and executes training, evaluation, or both procedures while generating a quality metric.\n","\n","By analyzing these components, we can delve into the workings and effectiveness of the existing search function in Mase."]},{"cell_type":"markdown","metadata":{"id":"G2zdGe7VA82g"},"source":["#Turning your network to a graph\n","\n","We follow a similar procedure of what you have tried in lab2 to now produce a MaseGraph, this is converted from your pre-trained JSC model:"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Z16mnfS8BM9o"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"]}],"source":["import sys\n","import logging\n","import os\n","from pathlib import Path\n","from pprint import pprint as pp\n","\n","# # figure out the correct path\n","# machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n","# assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n","# sys.path.append(str(machop_path))\n","\n","from chop.dataset import MaseDataModule, get_dataset_info\n","from chop.tools.logger import set_logging_verbosity\n","\n","from chop.passes.graph.analysis import (\n","    report_node_meta_param_analysis_pass,\n","    profile_statistics_analysis_pass,\n",")\n","from chop.passes.graph import (\n","    add_common_metadata_analysis_pass,\n","    init_metadata_analysis_pass,\n","    add_software_metadata_analysis_pass,\n",")\n","from chop.tools.get_input import InputGenerator\n","from chop.ir.graph.mase_graph import MaseGraph\n","\n","from chop.models import get_model_info, get_model\n","\n","\n","\n","\n","set_logging_verbosity(\"info\")\n","\n","batch_size = 8\n","model_name = \"jsc-tiny\"\n","dataset_name = \"jsc\"\n","\n","\n","data_module = MaseDataModule(\n","    name=dataset_name,\n","    batch_size=batch_size,\n","    model_name=model_name,\n","    num_workers=0,\n","    # custom_dataset_cache_path=\"../../chop/dataset\"\n",")\n","data_module.prepare_data()\n","data_module.setup()\n","\n","model_info = get_model_info(model_name)\n","model = get_model(\n","    model_name,\n","    task=\"cls\",\n","    dataset_info=data_module.dataset_info,\n","    pretrained=False,\n","    checkpoint = None)\n","\n","input_generator = InputGenerator(\n","    data_module=data_module,\n","    model_info=model_info,\n","    task=\"cls\",\n","    which_dataloader=\"train\",\n",")\n","\n","dummy_in = next(iter(input_generator))\n","_ = model(**dummy_in)\n","\n","# generate the mase graph and initialize node metadata\n","mg = MaseGraph(model=model)"]},{"cell_type":"markdown","metadata":{"id":"Lxs3Co8qY7Ea"},"source":["#Defining a search space\n","\n","Based on the previous `pass_args` template, the following code is utilized to generate a search space. The search space is constructed by combining different weight and data configurations in precision setups."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"JikYP98wZJPx"},"outputs":[],"source":["pass_args = {\n","\"by\": \"type\",\n","\"default\": {\"config\": {\"name\": None}},\n","\"linear\": {\n","        \"config\": {\n","            \"name\": \"integer\",\n","            # data\n","            \"data_in_width\": 8,\n","            \"data_in_frac_width\": 4,\n","            # weight\n","            \"weight_width\": 8,\n","            \"weight_frac_width\": 4,\n","            # bias\n","            \"bias_width\": 8,\n","            \"bias_frac_width\": 4,\n","        }\n","},}\n","\n","import copy\n","# build a search space\n","data_in_frac_widths = [(16, 8), (8, 6), (8, 4), (4, 2)]\n","w_in_frac_widths = [(16, 8), (8, 6), (8, 4), (4, 2)]\n","search_spaces = []\n","for d_config in data_in_frac_widths:\n","    for w_config in w_in_frac_widths:\n","        pass_args['linear']['config']['data_in_width'] = d_config[0]\n","        pass_args['linear']['config']['data_in_frac_width'] = d_config[1]\n","        pass_args['linear']['config']['weight_width'] = w_config[0]\n","        pass_args['linear']['config']['weight_frac_width'] = w_config[1]\n","        # dict.copy() and dict(dict) only perform shallow copies\n","        # in fact, only primitive data types in python are doing implicit copy when a = b happens\n","        search_spaces.append(copy.deepcopy(pass_args))"]},{"cell_type":"markdown","metadata":{"id":"H8XLOES6ZWOz"},"source":["## Defining a search strategy and a runner\n","\n","The code provided below consists of two main `for` loops. The first `for` loop executes a straightforward brute-force search, enabling the iteration through the previously defined search space.\n","\n","In contrast, the second `for` loop retrieves training samples from the train data loader. These samples are then utilized to generate accuracy and loss values, which serve as potential quality metrics for evaluating the system's performance.\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"]}],"source":["#to run it again\n","import sys\n","import logging\n","import os\n","from pathlib import Path\n","from pprint import pprint as pp\n","\n","# # figure out the correct path\n","# machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n","# assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n","# sys.path.append(str(machop_path))\n","\n","from chop.dataset import MaseDataModule, get_dataset_info\n","from chop.tools.logger import set_logging_verbosity\n","\n","from chop.passes.graph.analysis import (\n","    report_node_meta_param_analysis_pass,\n","    profile_statistics_analysis_pass,\n",")\n","from chop.passes.graph import (\n","    add_common_metadata_analysis_pass,\n","    init_metadata_analysis_pass,\n","    add_software_metadata_analysis_pass,\n",")\n","from chop.tools.get_input import InputGenerator\n","from chop.ir.graph.mase_graph import MaseGraph\n","\n","from chop.models import get_model_info, get_model\n","\n","\n","\n","\n","set_logging_verbosity(\"info\")\n","\n","batch_size = 8\n","model_name = \"jsc-tiny\"\n","dataset_name = \"jsc\"\n","\n","\n","data_module = MaseDataModule(\n","    name=dataset_name,\n","    batch_size=batch_size,\n","    model_name=model_name,\n","    num_workers=0,\n","    # custom_dataset_cache_path=\"../../chop/dataset\"\n",")\n","data_module.prepare_data()\n","data_module.setup()\n","\n","model_info = get_model_info(model_name)\n","model = get_model(\n","    model_name,\n","    task=\"cls\",\n","    dataset_info=data_module.dataset_info,\n","    pretrained=False,\n","    checkpoint = None)\n","\n","input_generator = InputGenerator(\n","    data_module=data_module,\n","    model_info=model_info,\n","    task=\"cls\",\n","    which_dataloader=\"train\",\n",")\n","\n","dummy_in = next(iter(input_generator))\n","_ = model(**dummy_in)\n","\n","# generate the mase graph and initialize node metadata\n","mg = MaseGraph(model=model)\n","\n","pass_args = {\n","\"by\": \"type\",\n","\"default\": {\"config\": {\"name\": None}},\n","\"linear\": {\n","        \"config\": {\n","            \"name\": \"integer\",\n","            # data\n","            \"data_in_width\": 8,\n","            \"data_in_frac_width\": 4,\n","            # weight\n","            \"weight_width\": 8,\n","            \"weight_frac_width\": 4,\n","            # bias\n","            \"bias_width\": 8,\n","            \"bias_frac_width\": 4,\n","        }\n","},}\n","\n","import copy\n","# build a search space\n","data_in_frac_widths = [(16, 8), (8, 6), (8, 4), (4, 2)]\n","w_in_frac_widths = [(16, 8), (8, 6), (8, 4), (4, 2)]\n","search_spaces = []\n","for d_config in data_in_frac_widths:\n","    for w_config in w_in_frac_widths:\n","        pass_args['linear']['config']['data_in_width'] = d_config[0]\n","        pass_args['linear']['config']['data_in_frac_width'] = d_config[1]\n","        pass_args['linear']['config']['weight_width'] = w_config[0]\n","        pass_args['linear']['config']['weight_frac_width'] = w_config[1]\n","        # dict.copy() and dict(dict) only perform shallow copies\n","        # in fact, only primitive data types in python are doing implicit copy when a = b happens\n","        search_spaces.append(copy.deepcopy(pass_args))"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"pjbFnH-hZZ55"},"outputs":[{"name":"stdout","output_type":"stream","text":["data_in: [16,8], weight: [16,8], bias: [8,4], The average time is 0.0005572523389543806\n","data_in: [16,8], weight: [8,6], bias: [8,4], The average time is 0.0006615434374128069\n","data_in: [16,8], weight: [8,4], bias: [8,4], The average time is 0.0006987707955496651\n","data_in: [16,8], weight: [4,2], bias: [8,4], The average time is 0.0003477505275181362\n","data_in: [8,6], weight: [16,8], bias: [8,4], The average time is 0.0003485679626464844\n","data_in: [8,6], weight: [8,6], bias: [8,4], The average time is 0.00032632691519601006\n","data_in: [8,6], weight: [8,4], bias: [8,4], The average time is 0.00031246457781110493\n","data_in: [8,6], weight: [4,2], bias: [8,4], The average time is 0.0003237724304199219\n","data_in: [8,4], weight: [16,8], bias: [8,4], The average time is 0.00036845888410295757\n","data_in: [8,4], weight: [8,6], bias: [8,4], The average time is 0.0003019741603306362\n","data_in: [8,4], weight: [8,4], bias: [8,4], The average time is 0.00030241693769182475\n","data_in: [8,4], weight: [4,2], bias: [8,4], The average time is 0.0002949237823486328\n","data_in: [4,2], weight: [16,8], bias: [8,4], The average time is 0.000308922358921596\n","data_in: [4,2], weight: [8,6], bias: [8,4], The average time is 0.00037363597324916294\n","data_in: [4,2], weight: [8,4], bias: [8,4], The average time is 0.0002923011779785156\n","data_in: [4,2], weight: [4,2], bias: [8,4], The average time is 0.00032557759966169087\n"]}],"source":["# grid search\n","import torch\n","from torchmetrics.classification import MulticlassAccuracy\n","import time\n","from chop.passes.graph.transforms import (\n","    quantize_transform_pass,\n","    summarize_quantization_analysis_pass,\n",")\n","\n","mg, _ = init_metadata_analysis_pass(mg, None)\n","mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n","mg, _ = add_software_metadata_analysis_pass(mg, None)\n","\n","metric = MulticlassAccuracy(num_classes=5)\n","num_batchs = 5\n","\n","recorded_time=[]\n","for i, config in enumerate(search_spaces):\n","    mg, _ = quantize_transform_pass(mg, config)\n","    j = 0\n","\n","    # this is the inner loop, where we also call it as a runner.\n","    time_singe=[]\n","    for inputs in data_module.train_dataloader():\n","        start_time=time.time()\n","        xs, ys = inputs\n","        preds = mg.model(xs)\n","        end_time=time.time()\n","        time_this=end_time-start_time\n","        time_singe.append(time_this)\n","        \n","        if j > num_batchs:\n","\n","            break\n","        j += 1\n","    time_avg=sum(time_singe)/len(time_singe)\n","    data_in_width=config[\"linear\"][\"config\"][\"data_in_width\"]\n","    data_in_frac_width = config[\"linear\"][\"config\"][\"data_in_frac_width\"]\n","    weight_width = config[\"linear\"][\"config\"][\"weight_width\"]\n","    weight_frac_width = config[\"linear\"][\"config\"][\"weight_frac_width\"]\n","    bias_width = config[\"linear\"][\"config\"][\"bias_width\"]\n","    bias_frac_width = config[\"linear\"][\"config\"][\"bias_frac_width\"]\n","    \n","    # Prepare and print the configuration information with all requested parameters\n","    print(f\"data_in: [{data_in_width},{data_in_frac_width}], weight: [{weight_width},{weight_frac_width}], \"\n","          f\"bias: [{bias_width},{bias_frac_width}], The average time is {time_avg}\")\n","    recorded_time.append(time_avg)\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'name': 'integer', 'data_in_width': 16, 'data_in_frac_width': 8, 'weight_width': 16, 'weight_frac_width': 8, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 16, 'data_in_frac_width': 8, 'weight_width': 8, 'weight_frac_width': 6, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 16, 'data_in_frac_width': 8, 'weight_width': 8, 'weight_frac_width': 4, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 16, 'data_in_frac_width': 8, 'weight_width': 4, 'weight_frac_width': 2, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 8, 'data_in_frac_width': 6, 'weight_width': 16, 'weight_frac_width': 8, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 8, 'data_in_frac_width': 6, 'weight_width': 8, 'weight_frac_width': 6, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 8, 'data_in_frac_width': 6, 'weight_width': 8, 'weight_frac_width': 4, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 8, 'data_in_frac_width': 6, 'weight_width': 4, 'weight_frac_width': 2, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 8, 'data_in_frac_width': 4, 'weight_width': 16, 'weight_frac_width': 8, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 8, 'data_in_frac_width': 4, 'weight_width': 8, 'weight_frac_width': 6, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 8, 'data_in_frac_width': 4, 'weight_width': 8, 'weight_frac_width': 4, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 8, 'data_in_frac_width': 4, 'weight_width': 4, 'weight_frac_width': 2, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 4, 'data_in_frac_width': 2, 'weight_width': 16, 'weight_frac_width': 8, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 4, 'data_in_frac_width': 2, 'weight_width': 8, 'weight_frac_width': 6, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 4, 'data_in_frac_width': 2, 'weight_width': 8, 'weight_frac_width': 4, 'bias_width': 8, 'bias_frac_width': 4}\n","{'name': 'integer', 'data_in_width': 4, 'data_in_frac_width': 2, 'weight_width': 4, 'weight_frac_width': 2, 'bias_width': 8, 'bias_frac_width': 4}\n"]}],"source":["for i, config in enumerate(search_spaces):\n","    print(config[\"linear\"][\"config\"])"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0, 680.0]\n"]}],"source":["from chop.passes.graph.analysis.flop_estimator import FLOP_pass_ziyun\n","import torch\n","from torchmetrics.classification import MulticlassAccuracy\n","import time\n","from chop.passes.graph.transforms import (\n","    quantize_transform_pass,\n","    summarize_quantization_analysis_pass,\n",")\n","\n","mg, _ = init_metadata_analysis_pass(mg, None)\n","mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n","mg, _ = add_software_metadata_analysis_pass(mg, None)\n","\n","metric = MulticlassAccuracy(num_classes=5)\n","num_batchs = 1\n","# This first loop is basically our search strategy,\n","# in this case, it is a simple brute force search\n","\n","recorded_accs = []\n","recorded_loss=[]\n","recorded_FLOP=[]\n","for i, config in enumerate(search_spaces):\n","    mg, _ = quantize_transform_pass(mg, config)\n","    j = 0\n","\n","\n","    for inputs in data_module.train_dataloader():\n","        flop=FLOP_pass_ziyun.flop_pass_report(mg)\n","        time_singe.append(time_this)\n","        recorded_FLOP.append(flop)\n","        if j > num_batchs:\n","\n","            break\n","\n","        j += 1\n","    time_avg=sum(time_singe)/len(time_singe)\n","    recorded_time.append(time_avg)\n","print(recorded_FLOP)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["display( )"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"data":{"text/plain":["'placeholder'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["dict_keys(['common', 'software', 'hardware'])"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'batch_norm1d'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["dict_keys(['common', 'software', 'hardware'])"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'relu'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["dict_keys(['common', 'software', 'hardware'])"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'linear'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["dict_keys(['common', 'software', 'hardware'])"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'relu'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["dict_keys(['common', 'software', 'hardware'])"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["'output'"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["dict_keys(['common', 'software', 'hardware'])"]},"metadata":{},"output_type":"display_data"}],"source":["for node in mg.fx_graph.nodes:\n","            display(node.meta[\"mase\"].parameters[\"common\"][\"mase_op\"])\n","            display(node.meta[\"mase\"].parameters.keys())\n","\n","\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'MaseGraph' object has no attribute 'in_features'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m display(\u001b[43mmg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_features\u001b[49m)\n","\u001b[0;31mAttributeError\u001b[0m: 'MaseGraph' object has no attribute 'in_features'"]}],"source":["display(mg.in_features)"]},{"cell_type":"markdown","metadata":{"id":"67C6-KNkamKF"},"source":["We now have the following task for you:\n","\n","1. Explore additional metrics that can serve as quality metrics for the search process. For example, you can consider metrics such as latency, model size, or the number of FLOPs (floating-point operations) involved in the model.\n","\n","2. Implement some of these additional metrics and attempt to combine them with the accuracy or loss quality metric. It's important to note that in this particular case, accuracy and loss actually serve as the same quality metric (do you know why?).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bxv08DrXZHFt"},"source":["# The search command in the MASE flow\n","\n","The search flow implemented in MASE is very similar to the one that you have constructed manually, the overall flow is implemented in [search.py](../../machop/chop/actions/search/search.py), the following bullet points provide you pointers to the code base.\n","\n","- MaseGraph: this is the [MaseGraph](../../machop/chop/passes/graph/mase_graph.py) that you have used in lab2.\n","- Search space: The base class is implemented in [base.py](../../machop/chop/actions/search/search_space/base.py) , where in the same folder you can see a range of different supported search spaces.\n","- Search strategy: Similar to the search space, you can find a a base class [definition](../../machop/chop/actions/search/strategies/base.py), where different strategies are also defined in the same folder.\n","- Runner: Different [runners](../../machop/chop/actions/search/strategies/runners) can produce different metrics, they may also use `transforms` to help compute certain search metrics.\n","\n","This enables one to execute the search through the MASE command line interface, remember to change the name after the `--load` option.\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"dOi0xZ8PCX8q"},"outputs":[{"name":"stdout","output_type":"stream","text":["/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n","  return torch._C._cuda_getDeviceCount() > 0\n","/rds/general/user/zf923/home/mase_ziyun/machop/chop/actions/simulate.py:3: UserWarning: Python runners and associated APIs are an experimental feature and subject to change.\n","  from cocotb.runner import get_runner, get_results\n","Seed set to 0\n","+-------------------------+--------------------------+--------------------------+--------------------------+--------------------------+\n","| Name                    |         Default          |       Config. File       |     Manual Override      |        Effective         |\n","+-------------------------+--------------------------+--------------------------+--------------------------+--------------------------+\n","| task                    |      \u001b[38;5;8mclassification\u001b[0m      |           cls            |                          |           cls            |\n","| load_name               |           \u001b[38;5;8mNone\u001b[0m           | \u001b[38;5;8m/rds/general/user/zf923/\u001b[0m | /rds/general/user/zf923/ | /rds/general/user/zf923/ |\n","|                         |                          | \u001b[38;5;8mhome/mase/mase_output/js\u001b[0m | home/mase/mase_output/js | home/mase/mase_output/js |\n","|                         |                          | \u001b[38;5;8mc-tiny_classification_js\u001b[0m | c-tiny_classification_js | c-tiny_classification_js |\n","|                         |                          | \u001b[38;5;8mc_2024-01-31/software/tr\u001b[0m | c_2024-01-31/software/tr | c_2024-01-31/software/tr |\n","|                         |                          |  \u001b[38;5;8maining_ckpts/best.ckpt\u001b[0m  |  aining_ckpts/best.ckpt  |  aining_ckpts/best.ckpt  |\n","| load_type               |            \u001b[38;5;8mmz\u001b[0m            |            pl            |                          |            pl            |\n","| batch_size              |           \u001b[38;5;8m128\u001b[0m            |           512            |                          |           512            |\n","| to_debug                |          False           |                          |                          |          False           |\n","| log_level               |           info           |                          |                          |           info           |\n","| report_to               |       tensorboard        |                          |                          |       tensorboard        |\n","| seed                    |            \u001b[38;5;8m0\u001b[0m             |            42            |                          |            42            |\n","| quant_config            |           None           |                          |                          |           None           |\n","| training_optimizer      |           adam           |                          |                          |           adam           |\n","| trainer_precision       |         16-mixed         |                          |                          |         16-mixed         |\n","| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |           0.01           |                          |           0.01           |\n","| weight_decay            |            0             |                          |                          |            0             |\n","| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |            5             |                          |            5             |\n","| max_steps               |            -1            |                          |                          |            -1            |\n","| accumulate_grad_batches |            1             |                          |                          |            1             |\n","| log_every_n_steps       |            \u001b[38;5;8m50\u001b[0m            |            5             |                          |            5             |\n","| num_workers             |           256            |                          |                          |           256            |\n","| num_devices             |            1             |                          |                          |            1             |\n","| num_nodes               |            1             |                          |                          |            1             |\n","| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |           cpu            |                          |           cpu            |\n","| strategy                |           auto           |                          |                          |           auto           |\n","| is_to_auto_requeue      |          False           |                          |                          |          False           |\n","| github_ci               |          False           |                          |                          |          False           |\n","| disable_dataset_cache   |          False           |                          |                          |          False           |\n","| target                  |   xcu250-figd2104-2L-e   |                          |                          |   xcu250-figd2104-2L-e   |\n","| num_targets             |           100            |                          |                          |           100            |\n","| is_pretrained           |          False           |                          |                          |          False           |\n","| max_token_len           |           512            |                          |                          |           512            |\n","| project_dir             | /rds/general/user/zf923/ |                          |                          | /rds/general/user/zf923/ |\n","|                         | home/mase_ziyun/mase_out |                          |                          | home/mase_ziyun/mase_out |\n","|                         |           put            |                          |                          |           put            |\n","| project                 |           \u001b[38;5;8mNone\u001b[0m           |         jsc-tiny         |                          |         jsc-tiny         |\n","| model                   |           \u001b[38;5;8mNone\u001b[0m           |         jsc-tiny         |                          |         jsc-tiny         |\n","| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |           jsc            |                          |           jsc            |\n","+-------------------------+--------------------------+--------------------------+--------------------------+--------------------------+\n","\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-tiny'...\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /rds/general/user/zf923/home/mase_ziyun/mase_output/jsc-tiny\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /rds/general/user/zf923/home/mase/mase_output/jsc-tiny_classification_jsc_2024-01-31/software/training_ckpts/best.ckpt\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mLoaded model from /rds/general/user/zf923/home/mase/mase_output/jsc-tiny_classification_jsc_2024-01-31/software/training_ckpts/best.ckpt.\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mBuilding search space...\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mSearch started...\u001b[0m\n","/rds/general/user/zf923/home/mase_ziyun/machop/chop/actions/search/strategies/optuna.py:57: ExperimentalWarning: BruteForceSampler is experimental (supported from v3.1.0). The interface can change in the future.\n","  sampler = optuna.samplers.BruteForceSampler()\n"," 30%|██████▌               | 6/20 [03:58<09:09, 39.27s/it, 238.07/20000 seconds]Traceback (most recent call last):\n","  File \"/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n","    finalizer()\n","  File \"/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n","    res = self._callback(*self._args, **self._kwargs)\n","  File \"/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n","    rmtree(tempdir)\n","  File \"/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/shutil.py\", line 731, in rmtree\n","    onerror(os.rmdir, path, sys.exc_info())\n","  File \"/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/shutil.py\", line 729, in rmtree\n","    os.rmdir(path)\n","OSError: [Errno 39] Directory not empty: '/rds/general/ephemeral/user/zf923/ephemeral/pymp-snim1jwp'\n"," 90%|██████████████████▉  | 18/20 [12:31<01:23, 41.74s/it, 751.30/20000 seconds]\n","\u001b[32mINFO    \u001b[0m \u001b[34mBest trial(s):\n","Best trial(s):\n","|    |   number | software_metrics                   | hardware_metrics                                  | scaled_metrics                               |\n","|----+----------+------------------------------------+---------------------------------------------------+----------------------------------------------|\n","|  0 |        0 | {'loss': 1.547, 'accuracy': 0.312} | {'average_bitwidth': 2.0, 'memory_density': 16.0} | {'accuracy': 0.312, 'average_bitwidth': 0.4} |\n","|  1 |        1 | {'loss': 1.549, 'accuracy': 0.323} | {'average_bitwidth': 4.0, 'memory_density': 8.0}  | {'accuracy': 0.323, 'average_bitwidth': 0.8} |\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mSearching is completed\u001b[0m\n"]}],"source":["!./ch search --config configs/examples/jsc_toy_by_type.toml --load /rds/general/user/zf923/home/mase/mase_output/jsc-tiny_classification_jsc_2024-01-31/software/training_ckpts/best.ckpt"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/rds/general/user/zf923/home/anaconda3/envs/mase/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n","  return torch._C._cuda_getDeviceCount() > 0\n","/rds/general/user/zf923/home/mase_ziyun/machop/chop/actions/simulate.py:3: UserWarning: Python runners and associated APIs are an experimental feature and subject to change.\n","  from cocotb.runner import get_runner, get_results\n","Seed set to 0\n","+-------------------------+--------------------------+--------------------------+--------------------------+--------------------------+\n","| Name                    |         Default          |       Config. File       |     Manual Override      |        Effective         |\n","+-------------------------+--------------------------+--------------------------+--------------------------+--------------------------+\n","| task                    |      \u001b[38;5;8mclassification\u001b[0m      |           cls            |                          |           cls            |\n","| load_name               |           \u001b[38;5;8mNone\u001b[0m           | \u001b[38;5;8m/rds/general/user/zf923/\u001b[0m | /rds/general/user/zf923/ | /rds/general/user/zf923/ |\n","|                         |                          | \u001b[38;5;8mhome/mase/mase_output/js\u001b[0m | home/mase/mase_output/js | home/mase/mase_output/js |\n","|                         |                          | \u001b[38;5;8mc-tiny_classification_js\u001b[0m | c-tiny_classification_js | c-tiny_classification_js |\n","|                         |                          | \u001b[38;5;8mc_2024-01-31/software/tr\u001b[0m | c_2024-01-31/software/tr | c_2024-01-31/software/tr |\n","|                         |                          |  \u001b[38;5;8maining_ckpts/best.ckpt\u001b[0m  |  aining_ckpts/best.ckpt  |  aining_ckpts/best.ckpt  |\n","| load_type               |            \u001b[38;5;8mmz\u001b[0m            |            pl            |                          |            pl            |\n","| batch_size              |           \u001b[38;5;8m128\u001b[0m            |           512            |                          |           512            |\n","| to_debug                |          False           |                          |                          |          False           |\n","| log_level               |           info           |                          |                          |           info           |\n","| report_to               |       tensorboard        |                          |                          |       tensorboard        |\n","| seed                    |            \u001b[38;5;8m0\u001b[0m             |            42            |                          |            42            |\n","| quant_config            |           None           |                          |                          |           None           |\n","| training_optimizer      |           adam           |                          |                          |           adam           |\n","| trainer_precision       |         16-mixed         |                          |                          |         16-mixed         |\n","| learning_rate           |          \u001b[38;5;8m1e-05\u001b[0m           |           0.01           |                          |           0.01           |\n","| weight_decay            |            0             |                          |                          |            0             |\n","| max_epochs              |            \u001b[38;5;8m20\u001b[0m            |            5             |                          |            5             |\n","| max_steps               |            -1            |                          |                          |            -1            |\n","| accumulate_grad_batches |            1             |                          |                          |            1             |\n","| log_every_n_steps       |            \u001b[38;5;8m50\u001b[0m            |            5             |                          |            5             |\n","| num_workers             |           256            |                          |                          |           256            |\n","| num_devices             |            1             |                          |                          |            1             |\n","| num_nodes               |            1             |                          |                          |            1             |\n","| accelerator             |           \u001b[38;5;8mauto\u001b[0m           |           cpu            |                          |           cpu            |\n","| strategy                |           auto           |                          |                          |           auto           |\n","| is_to_auto_requeue      |          False           |                          |                          |          False           |\n","| github_ci               |          False           |                          |                          |          False           |\n","| disable_dataset_cache   |          False           |                          |                          |          False           |\n","| target                  |   xcu250-figd2104-2L-e   |                          |                          |   xcu250-figd2104-2L-e   |\n","| num_targets             |           100            |                          |                          |           100            |\n","| is_pretrained           |          False           |                          |                          |          False           |\n","| max_token_len           |           512            |                          |                          |           512            |\n","| project_dir             | /rds/general/user/zf923/ |                          |                          | /rds/general/user/zf923/ |\n","|                         | home/mase_ziyun/mase_out |                          |                          | home/mase_ziyun/mase_out |\n","|                         |           put            |                          |                          |           put            |\n","| project                 |           \u001b[38;5;8mNone\u001b[0m           |         jsc-tiny         |                          |         jsc-tiny         |\n","| model                   |           \u001b[38;5;8mNone\u001b[0m           |         jsc-tiny         |                          |         jsc-tiny         |\n","| dataset                 |           \u001b[38;5;8mNone\u001b[0m           |           jsc            |                          |           jsc            |\n","+-------------------------+--------------------------+--------------------------+--------------------------+--------------------------+\n","\u001b[32mINFO    \u001b[0m \u001b[34mInitialising model 'jsc-tiny'...\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mInitialising dataset 'jsc'...\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mProject will be created at /rds/general/user/zf923/home/mase_ziyun/mase_output/jsc-tiny\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /rds/general/user/zf923/home/mase/mase_output/jsc-tiny_classification_jsc_2024-01-31/software/training_ckpts/best.ckpt\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mLoaded model from /rds/general/user/zf923/home/mase/mase_output/jsc-tiny_classification_jsc_2024-01-31/software/training_ckpts/best.ckpt.\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mBuilding search space...\u001b[0m\n","\u001b[32mINFO    \u001b[0m \u001b[34mSearch started...\u001b[0m\n","/rds/general/user/zf923/home/mase_ziyun/machop/chop/actions/search/strategies/optuna.py:57: ExperimentalWarning: BruteForceSampler is experimental (supported from v3.1.0). The interface can change in the future.\n","  sampler = optuna.samplers.BruteForceSampler()\n"," 40%|█████████▌              | 2/5 [01:17<01:55, 38.45s/it, 77.26/20000 seconds]^C\n"]}],"source":["!./ch search --config configs/examples/jsc_toy_by_type.toml --load /rds/general/user/zf923/home/mase/mase_output/jsc-tiny_classification_jsc_2024-01-31/software/training_ckpts/best.ckpt"]},{"cell_type":"markdown","metadata":{"id":"gvzdE4MSCc3g"},"source":["In this scenario, the search functionality is specified in the `toml` configuration file rather than via command-line inputs. This approach is adopted due to the multitude of configuration parameters that need to be set; encapsulating them within a single, elegant configuration file enhances reproducibility.\n","\n","In `jsc_toy_by_type.toml`, the `search_space` configuration is set in `search.search_space`, the search strategy is configured via `search.strategy`. If you are not familiar with the `toml` syntax, you can read [here](https://toml.io/en/v1.0.0)."]},{"cell_type":"markdown","metadata":{"id":"aLrs_IVDIthZ"},"source":["> In order to accomplish the following task, it is necessary to make direct modifications to the code base. This can be challenging within the Colab environment. **It is recommended to implement the task on a local setup and utilize Colab strictly as a server to execute the search command above.** Consider Colab as a dedicated server for this purpose."]},{"cell_type":"markdown","metadata":{"id":"BE4oiC-2CEFR"},"source":["With now an understanding of how the MASE flow work, consider the following tasks\n","\n","3. Implement the brute-force search as an additional search method within the system, this would be a new search strategy in MASE.\n","4. Compare the brute-force search with the TPE based search, in terms of sample efficiency. Comment on the performance difference between the two search methods."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1NINl2shLe5Uxp2IYkxmqXCJofGxBRCZs","timestamp":1705282336697}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
